{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bf6da588",
      "metadata": {
        "id": "bf6da588"
      },
      "source": [
        "# **Buckle Up ! We are starting our week 2 roller coaster**\n",
        "\n",
        "In our first week we covered some theoritical concepts and completed our setup so its time we start building!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6b55c5",
      "metadata": {
        "id": "ca6b55c5"
      },
      "source": [
        "## üìì**Conversational AI Concepts & Model Pipelines**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b7ace2",
      "metadata": {
        "id": "f1b7ace2"
      },
      "source": [
        "üéØ By the end of this week, you will:\n",
        "\n",
        "- Understand LLMs, STT, TTS models and their roles.\n",
        "\n",
        "- Know how to connect to LLMs with APIs (Groq as example).\n",
        "\n",
        "- Use Python (requests + JSON) for API interaction.\n",
        "\n",
        "- Start building a basic chatbot with memory and preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e3c5144",
      "metadata": {
        "id": "8e3c5144"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Large Language Models (LLMs) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03968dc4",
      "metadata": {
        "id": "03968dc4"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 1**: What is an LLM?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dd894fc",
      "metadata": {
        "id": "9dd894fc"
      },
      "source": [
        "üëâ It‚Äôs like a super-smart text predictor that can read, understand, and generate human-like sentences.\n",
        "\n",
        "You give it some words ‚Üí it guesses the next words in a way that makes sense.\n",
        "\n",
        "For example:\n",
        "\n",
        "1) You ask a question ‚Üí it gives you an answer.\n",
        "\n",
        "2) You write a sentence ‚Üí it can complete it.\n",
        "\n",
        "3) You give it a topic ‚Üí it can write an essay, code, or even a story.\n",
        "\n",
        "So, its a type of AI trained on huge amounts of text data to generate or understand text.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77076ddc",
      "metadata": {
        "id": "77076ddc"
      },
      "source": [
        "### Types of LLMs\n",
        "\n",
        "1. Encoder-only models (e.g., BERT)\n",
        "\n",
        "    - Best for understanding text (classification, sentiment analysis, embeddings).\n",
        "\n",
        "    - ‚ùå Not good at generating text.\n",
        "\n",
        "2. Decoder-only models (e.g., GPT, LLaMA, Mistral)\n",
        "\n",
        "    - Best for text generation (chatbots, writing, summarization).\n",
        "\n",
        "    - What we use in chatbots.\n",
        "\n",
        "3. Encoder-decoder models (e.g., T5, BART)\n",
        "\n",
        "    - Good at transforming text (translation, summarization, Q&A)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339099fe",
      "metadata": {
        "id": "339099fe"
      },
      "source": [
        "### Must-Knows about LLMs\n",
        "\n",
        "- They don‚Äôt ‚Äúthink‚Äù like humans ‚Üí They predict text based on training.\n",
        "\n",
        "- Garbage in ‚Üí garbage out: Poor prompts = poor answers.\n",
        "\n",
        "- Token limits: Models can only ‚Äúsee‚Äù a certain number of words at a time.\n",
        "\n",
        "- Biases: Trained on internet text ‚Üí may reflect biases/errors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b1b2dd4",
      "metadata": {
        "id": "8b1b2dd4"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7753565a",
      "metadata": {
        "id": "7753565a"
      },
      "source": [
        "1. Why might a chatbot built on BERT (encoder-only) struggle to answer open-ended questions?\n",
        "\n",
        "- Answer üëâA chatbot built on BERT (encoder-only) might struggle with open-ended questions because BERT is designed mainly for understanding and analyzing text, not for generating new responses. Since it lacks a decoder, it cannot naturally produce long, coherent answers beyond classification or extraction tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5feffca",
      "metadata": {
        "id": "a5feffca"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Speech-to-Text (STT) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9393abf7",
      "metadata": {
        "id": "9393abf7"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 2**: What is STT?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f54ac00",
      "metadata": {
        "id": "3f54ac00"
      },
      "source": [
        "üëâ listens to your voice and turns it into written text.\n",
        "\n",
        "- Converts **audio ‚Üí text**.\n",
        "- Enables voice input for conversational AI.\n",
        "- Think of it as the **ears** of the chatbot.\n",
        "\n",
        "**Popular STT Models**:\n",
        "\n",
        "1) **Whisper (OpenAI)** ‚Äì strong at multilingual speech recognition.\n",
        "2) **Google Speech-to-Text API** ‚Äì widely used, real-time transcription.\n",
        "3) **Vosk** ‚Äì lightweight, offline speech recognition.\n",
        "\n",
        "**Common Usages**\n",
        "\n",
        "1) Voice assistants (Alexa, Siri, Google Assistant).\n",
        "2) Automated captions in meetings or lectures.\n",
        "3) Voice-enabled customer support.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc99714c",
      "metadata": {
        "id": "cc99714c"
      },
      "source": [
        "### Must-Knows about STT\n",
        "\n",
        "- Accuracy depends on **noise, accents, clarity of speech**.\n",
        "\n",
        "- Some models need **internet connection** (API-based), others run **offline**.\n",
        "\n",
        "- Preprocessing audio (noise reduction) improves results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec23bf9a",
      "metadata": {
        "id": "ec23bf9a"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407d8a82",
      "metadata": {
        "id": "407d8a82"
      },
      "source": [
        "2. Why do you think meeting transcription apps like Zoom or Google Meet struggle when multiple people talk at once?\n",
        "\n",
        "- Answer üëâMeeting transcription apps like Zoom or Google Meet struggle when multiple people talk at once because speech recognition models are usually optimized for single-speaker input. Overlapping voices create noise, making it hard for the system to separate speakers and correctly align words with the right person, which reduces transcription accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2959a81",
      "metadata": {
        "id": "f2959a81"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Text-to-Speech (TTS) üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6650b62d",
      "metadata": {
        "id": "6650b62d"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚ùó **Question 3**: What is TTS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McIrJJ8u0Hv4"
      },
      "source": [
        "üëâ takes written text and speaks it out loud in a human-like voice.\n",
        "\n",
        "- Converts **text ‚Üí audio (speech)**.\n",
        "- Think of it as the **mouth** of the chatbot.\n",
        "- Makes AI ‚Äúspeak‚Äù naturally.\n",
        "\n",
        "**Popular TTS Models**:\n",
        "\n",
        "1) **Google TTS** ‚Äì supports many languages and voices.\n",
        "2) **Amazon Polly** ‚Äì lifelike voice synthesis with customization.\n",
        "3) **ElevenLabs** ‚Äì cutting-edge, realistic voice cloning.\n",
        "\n",
        "**Common Usages**\n",
        "\n",
        "1) Screen readers for visually impaired users.\n",
        "2) AI chatbots with voice output.\n",
        "3) Audiobooks or podcast generation.\n",
        "\n",
        "---"
      ],
      "id": "McIrJJ8u0Hv4"
    },
    {
      "cell_type": "markdown",
      "id": "cfdb2471",
      "metadata": {
        "id": "cfdb2471"
      },
      "source": [
        "### Must-Knows about TTS\n",
        "\n",
        "- Some voices sound robotic; others use **neural TTS** for natural tones.\n",
        "\n",
        "- Latency matters ‚Üí If too slow, conversation feels unnatural.\n",
        "\n",
        "- Some TTS services allow **custom voices**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee49cb51",
      "metadata": {
        "id": "ee49cb51"
      },
      "source": [
        "### üí° **Quick Questions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8f3eb2",
      "metadata": {
        "id": "ee8f3eb2"
      },
      "source": [
        "3. If you were designing a voice-based AI tutor, what qualities would you want in its TTS voice (tone, speed, clarity, etc.)?\n",
        "\n",
        "- Answer üëâIf I were designing a voice-based AI tutor, I‚Äôd want the TTS voice to have a clear and natural tone, moderate speed that adapts to the learner‚Äôs pace, and good pronunciation for easy understanding. It should also convey a friendly and encouraging style, with slight variations in intonation so it doesn‚Äôt sound robotic or monotonous."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8042c582",
      "metadata": {
        "id": "8042c582"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Using APIs for LLMs with Groq üåü"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sevOaEU02KG7",
        "outputId": "a5e482fe-65e2-4608-e82a-3a02423660a4"
      },
      "id": "sevOaEU02KG7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/131.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7889d8ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7889d8ee",
        "outputId": "7a57b812-d0f4-465a-a8b9-ac9d3182b5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Groq API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Conversational AI, also known as conversational artificial intelligence or chatbots, refers to the use of artificial intelligence (AI) to enable computers or online platforms to understand and respond to human language in a conversational manner.\n",
            "\n",
            "Conversational AI technologies have advanced significantly in recent years, allowing machines to understand the nuances of human conversation, including tone, context, and intent. This enables them to respond in a way that mimics human-like communication.\n",
            "\n",
            "Some common applications of conversational AI include:\n",
            "\n",
            "1. **Chatbots**: Virtual assistants that respond to user queries, provide support, and offer solutions to customer inquiries.\n",
            "2. **Virtual assistants**: Like Siri, Alexa, and Google Assistant, which can perform tasks, provide information, and control smart home devices.\n",
            "3. **Customer service**: AI-powered chatbots and virtual agents help customers resolve issues, answer questions, and provide support 24/7.\n",
            "4. **Language translation**: Systems that translate text or speech in real-time, facilitating global communication.\n",
            "5. **Dialogue systems**: Platforms that enable human-computer interaction through natural language understanding and response.\n",
            "\n",
            "Conversational AI employs various techniques, including:\n",
            "\n",
            "1. **Natural Language Processing (NLP)**: Analyzing and understanding human language.\n",
            "2. **Machine Learning (ML)**: Training AI models to learn from data and improve responses.\n",
            "3. **Rule-based systems**: Using pre-defined rules to generate responses.\n",
            "\n",
            "Conversational AI has numerous benefits, such as:\n",
            "\n",
            "1. **Improved customer experiences**: Fast, accurate, and personalized support.\n",
            "2. **Increased efficiency**: Automating routine tasks, freeing up human agents for more complex issues.\n",
            "3. **Cost savings**: Reducing the need for human customer support teams.\n",
            "\n",
            "However, conversational AI also raises concerns about:\n",
            "\n",
            "1. **Data privacy**: Collecting and storing user data, including conversations.\n",
            "2. **Security risks**: Potential vulnerabilities in AI systems, such as hacking or data breaches.\n",
            "3. **Bias and accuracy**: Ensuring AI responses are accurate, unbiased, and free from errors.\n",
            "\n",
            "Overall, conversational AI has transformed the way we interact with technology, offering numerous benefits and opportunities for innovation.\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import getpass\n",
        "\n",
        "api_key = getpass.getpass(\"Enter your Groq API key: \")\n",
        "\n",
        "client = Groq(api_key=api_key)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello! What is conversational AI?\"}]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56c20eb",
      "metadata": {
        "id": "a56c20eb"
      },
      "source": [
        "---\n",
        "\n",
        "## üåü Assignments üåü"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bcc2ce6",
      "metadata": {
        "id": "2bcc2ce6"
      },
      "source": [
        "### üìù Assignment 1: LLM Understanding\n",
        "\n",
        "* Write a short note (3‚Äì4 sentences) explaining the difference between **encoder-only, decoder-only, and encoder-decoder LLMs**.\n",
        "* Give one example usage of each.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "1) Encoder-only = the wise teacher (only understands and deeply analyzes the input).\n",
        "2) Decoder-only = the storyteller friend (only generates the next possible word).\n",
        "3) Encoder‚ÄìDecoder = the translator friend (first understands, then generates a new output).\n",
        "\n",
        "Encoder-only LLMs (like BERT) focus on understanding and representing input text, making them useful for classification, embeddings, and semantic search. Decoder-only LLMs (like GPT) specialize in generating text by predicting the next token, ideal for chatbots, story generation, and code completion. Encoder‚ÄìDecoder LLMs (like T5 or BART) combine both: the encoder processes the input while the decoder generates context-aware output, making them effective for tasks such as translation and summarization."
      ],
      "metadata": {
        "id": "SbAmNDdoCQX0"
      },
      "id": "SbAmNDdoCQX0"
    },
    {
      "cell_type": "markdown",
      "id": "370084b8",
      "metadata": {
        "id": "370084b8"
      },
      "source": [
        "### üìù Assignment 2: STT/TTS Exploration\n",
        "\n",
        "* Find **one STT model** and **one TTS model** (other than Whisper/Google).\n",
        "* Write down:\n",
        "\n",
        "  * What it does.\n",
        "  * One possible application."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "Speech-to-Text (STT) Model: **DeepSpeech (by Mozilla)**\n",
        "\n",
        "1) What it does:\n",
        "Converts spoken audio into written text using a recurrent neural network\n",
        "trained on large speech datasets.\n",
        "\n",
        "2) One possible application:\n",
        "Building a voice-controlled note-taking app where lectures or meetings are automatically transcribed into text.\n",
        "\n",
        "ext-to-Speech (TTS) Model: **VITS (Variational Inference Text-to-Speech, by Kakao Brain)**\n",
        "\n",
        "1) What it does: End-to-end model that directly generates high-quality, natural-sounding speech from text without needing separate components (like Tacotron + vocoder).\n",
        "\n",
        "2) One possible application: Audiobook generation, where long-form text can be converted into human-like narration automatically."
      ],
      "metadata": {
        "id": "Ue2ORlGkDMtR"
      },
      "id": "Ue2ORlGkDMtR"
    },
    {
      "cell_type": "markdown",
      "id": "84824b65",
      "metadata": {
        "id": "84824b65"
      },
      "source": [
        "### üìù Assignment 3: Build a Chatbot with Memory\n",
        "\n",
        "* Write a Python program that:\n",
        "\n",
        "  * Takes user input in a loop.\n",
        "  * Sends it to Groq API.\n",
        "  * Stores the last 5 messages in memory.\n",
        "  * Ends when user types `\"quit\"`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=\"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\")\n",
        "\n",
        "messages = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() == \"quit\":\n",
        "        print(\"Chat ended.\")\n",
        "        break\n",
        "\n",
        "    # Add user message\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    messages = messages[-5:]\n",
        "\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    reply = response.choices[0].message.content\n",
        "    print(\"Bot:\", reply)\n",
        "\n",
        "    # Add bot reply\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    messages = messages[-5:]  # keep only last 5 messages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVIG4ygVFEXX",
        "outputId": "ce057ecb-9034-491c-e004-30bc6968a662"
      },
      "id": "EVIG4ygVFEXX",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: hello\n",
            "Bot: Hello. How can I assist you today?\n",
            "You: i want to know about AI, define it in 5 sentences.\n",
            "Bot: Artificial Intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, reasoning, and problem-solving. AI systems use algorithms and data to make decisions, often without being explicitly programmed for a specific task. These systems can be designed to simulate human-like intelligence, allowing them to adapt and improve over time through machine learning and experience. AI has numerous applications across various industries, including healthcare, finance, transportation, and education, and is used in everyday technologies like virtual assistants and image recognition software. Overall, AI aims to create intelligent machines that can think and act like humans, augmenting human capabilities and improving the efficiency and accuracy of various processes.\n",
            "You: okay thanks\n",
            "Bot: I'm glad I could help introduce you to the concept of AI. If you have any more questions or want to learn more, feel free to ask!\n",
            "You: so how you feel today?\n",
            "Bot: I'm just a language model, I don't have feelings or emotions like humans do. I'm designed to process and respond to text-based input, and I don't have personal experiences or emotions. I'm always ready to help and provide information, 24/7! However, I can tell you about different emotions or help you explore how you're feeling if you'd like.\n",
            "You: tell me what was the first msg i send you?\n",
            "Bot: Your first message to me was \"okay thanks\".\n",
            "You: no that was 3rd msg?\n",
            "Bot: Your first message to me was actually \"so how you feel today?\".\n",
            "You: quit\n",
            "Chat ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aef3132",
      "metadata": {
        "id": "1aef3132"
      },
      "source": [
        "### üìù Assignment 4: Preprocessing Function\n",
        "\n",
        "* Write a function to clean user input:\n",
        "\n",
        "  * Lowercase text.\n",
        "  * Remove punctuation.\n",
        "  * Strip extra spaces.\n",
        "\n",
        "Test with: `\"  HELLo!!!  How ARE you?? \"`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "sample = \" HELLo!!! How ARE you?? \"\n",
        "print(\"Original:\", sample)\n",
        "print(\"Cleaned :\", clean_text(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9uneIF6G-JV",
        "outputId": "7c494c2b-6dcb-4f07-ea85-f9389d0f197a"
      },
      "id": "x9uneIF6G-JV",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  HELLo!!! How ARE you?? \n",
            "Cleaned : hello how are you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53027998",
      "metadata": {
        "id": "53027998"
      },
      "source": [
        "### üìù Assignment 5: Text Preprocessing\n",
        "\n",
        "* Write a function that:\n",
        "\n",
        "    * Converts text to lowercase.\n",
        "    * Removes punctuation & numbers.\n",
        "    * Removes stopwords (`the, is, and...`).\n",
        "    * Applies stemming or lemmatization.\n",
        "    * Removes words shorter than 3 characters.\n",
        "    * Keeps only nouns, verbs, and adjectives (using POS tagging)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk import pos_tag, word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPdMSN-gJZFG",
        "outputId": "29b1772c-5104-430c-d0e2-3fcb35979ba5"
      },
      "id": "MPdMSN-gJZFG",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "    words = [w for w in words if len(w) >= 3]\n",
        "    words = [PorterStemmer().stem(w) for w in words]\n",
        "    tagged = pos_tag(words)\n",
        "    words = [w for w, t in tagged if t.startswith((\"N\",\"V\",\"J\"))]\n",
        "    return words\n",
        "\n",
        "sample = \"Its September 2025, only 3 and a half month left in 2026!\"\n",
        "print(clean_text(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBLn3wjYIDJ-",
        "outputId": "6bd02e8a-4956-420f-d0c4-4868a6f203f9"
      },
      "id": "fBLn3wjYIDJ-",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['septemb', 'half', 'month', 'left']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb68c035",
      "metadata": {
        "id": "bb68c035"
      },
      "source": [
        "### üìù Assignment 6: Reflection\n",
        "\n",
        "* Answer in 2‚Äì3 sentences:\n",
        "\n",
        "    * Why is context memory important in chatbots?\n",
        "    * Why should beginners always check **API limits and pricing**?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Context memory is important in chatbots because it allows the system to remember past interactions, maintain continuity, and give more natural, human-like responses instead of treating each message in isolation. Beginners should always check API limits and pricing to avoid unexpected costs and to design their applications efficiently within usage constraints."
      ],
      "metadata": {
        "id": "pQMcfO8iJrX9"
      },
      "id": "pQMcfO8iJrX9"
    },
    {
      "cell_type": "markdown",
      "id": "4b787de4",
      "metadata": {
        "id": "4b787de4"
      },
      "source": [
        "---\n",
        "\n",
        "### **Hints:**\n",
        "\n",
        "1) Stemming:\n",
        "    - Cuts off word endings to get the ‚Äúroot.‚Äù\n",
        "    - Very mechanical ‚Üí may produce non-real words.\n",
        "    - Example:\n",
        "        - \"studies\" ‚Üí \"studi\"\n",
        "        - \"running\" ‚Üí \"run\"\n",
        "\n",
        "2) Lemmatization:\n",
        "    - Smarter ‚Üí uses vocabulary + grammar rules.\n",
        "    - Always gives a real word (the **lemma**).\n",
        "    - Example:\n",
        "        - \"studies\" ‚Üí \"study\"\n",
        "        - \"running\" ‚Üí \"run\"\n",
        "\n",
        "3) Part-of-Speech (POS) tagging means labeling each word in a sentence with its grammatical role ‚Äî like **noun, verb, adjective, adverb, pronoun, etc.**\n",
        "\n",
        "    - Example:\n",
        "        - Sentence ‚Üí *‚ÄúThe cat is sleeping on the mat.‚Äù*\n",
        "\n",
        "    - POS tags ‚Üí\n",
        "        - The ‚Üí Determiner (DT)\n",
        "        - cat ‚Üí Noun (NN)\n",
        "        - is ‚Üí Verb (VBZ)\n",
        "        - sleeping ‚Üí Verb (VBG)\n",
        "        - on ‚Üí Preposition (IN)\n",
        "        - the ‚Üí Determiner (DT)\n",
        "        - mat ‚Üí Noun (NN)\n",
        "\n",
        "    - **In short:** POS tagging helps machines understand **how words function in a sentence**, which is useful in NLP tasks like machine translation, text classification, and question answering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cec98bb",
      "metadata": {
        "id": "3cec98bb"
      },
      "source": [
        "---\n",
        "\n",
        "### ‚úÖ Recap\n",
        "\n",
        "This week you learned:\n",
        "\n",
        "* **LLMs**: Types, uses, must-knows.\n",
        "* **STT & TTS**: How they connect with LLMs.\n",
        "* **APIs**: Connecting to LLMs with Groq.\n",
        "* Built your first chatbot foundation."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}